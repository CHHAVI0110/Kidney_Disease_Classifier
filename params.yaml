# ==========================
# Image and base model parameters
# ==========================
IMAGE_SIZE: [224, 224, 3]     # (height, width, channels) -> required by Xception
INCLUDE_TOP: False            # exclude top fully connected layers, we add custom head
WEIGHTS: imagenet             # use pretrained ImageNet weights

# ==========================
# Training parameters
# ==========================
CLASSES: 4                    # number of classes (set according to your dataset)
LEARNING_RATE: 0.00005  # base learning rate for fine-tuning
FREEZE_TILL: 120          # how many layers to freeze initially
FINE_TUNE_LAST_N: 40      # unfreeze last N layers for fine-tuning
EPOCHS: 20               # total number of training epochs (use with EarlyStopping)
BATCH_SIZE: 16            # batch size for training
AUGMENTATION: true            # whether to apply data augmentation

# ==========================
# Regularization (anti-overfitting)
# ==========================
DROPOUT_RATE_HEAD: 0.5    # dropout for classification head
WEIGHT_DECAY: 0.0001         # L2 regularization
LABEL_SMOOTHING: 0.1          # soft labels to avoid overconfidence

# ==========================
# Model architecture
# ==========================
DENSE_UNITS: 512            # dense layer size before final softmax
OPTIMIZER: "adamw"  
          # "adam" or "adamw"
